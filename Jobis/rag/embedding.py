import json
import os
import shutil
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# ==========================================
# 1. ê²½ë¡œ ë° ì„¤ì •
# ==========================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
INPUT_FILE = os.path.join(BASE_DIR, 'data', 'processed', 'cleaned_data.json')
PERSIST_DIRECTORY = os.path.join(BASE_DIR, 'data', 'chroma_db')
EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L12-v2"

def load_processed_data():
    if not os.path.exists(INPUT_FILE):
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_FILE}")
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def create_documents(data):
    documents = []
    
    for item in data:
        # [ìˆ˜ì •ëœ ë¶€ë¶„] -------------------------------------------------------
        # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•´ ë³¸ë¬¸(page_content)ì— ê¸°ì—…ëª…ê³¼ ì‚°ì—… ì •ë³´ë¥¼ í¬í•¨ì‹œí‚µë‹ˆë‹¤.
        company_name = item.get('company_name', 'Unknown')
        industry = item.get('industry', 'Unknown')
        content_text = item.get('content', '')

        # AIê°€ ê²€ìƒ‰í•  ì‹¤ì œ í…ìŠ¤íŠ¸ êµ¬ì„±
        page_content = f"ê¸°ì—…ëª…: {company_name}\nì‚°ì—…ë¶„ì•¼: {industry}\në‚´ìš©: {content_text}"
        # -------------------------------------------------------------------
        
        metadata = {
            "company_name": company_name,
            "industry": industry,
            "type": item.get('type', 'Unknown'),
            "sentiment": item.get('sentiment', 'neutral'),
            "score": item.get('score', 0) if item.get('score') is not None else 0,
            "date": item.get('date', ''),
            "data_id": item.get('data_id', '')
        }
        
        doc = Document(page_content=page_content, metadata=metadata)
        documents.append(doc)
        
    return documents

def build_vector_db():
    print(f"ğŸ”„ 1. ë°ì´í„° ë¡œë”© ì¤‘... ({INPUT_FILE})")
    data = load_processed_data()
    
    print(f"ğŸ“„ 2. ë¬¸ì„œ ë³€í™˜ ì¤‘... (ì´ {len(data)}ê°œ í•­ëª©)")
    documents = create_documents(data)
    
    # ê¸°ì¡´ DB ì‚­ì œ í›„ ì¬ìƒì„± (ê¹¨ë—í•œ ìƒíƒœ ìœ ì§€ë¥¼ ìœ„í•´)
    if os.path.exists(PERSIST_DIRECTORY):
        print(f"ğŸ—‘ï¸  ê¸°ì¡´ DB ì‚­ì œ ì¤‘... ({PERSIST_DIRECTORY})")
        shutil.rmtree(PERSIST_DIRECTORY)

    print(f"ğŸ§© 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘... ({EMBEDDING_MODEL_NAME})")
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    print(f"ğŸ’¾ 4. ChromaDB ìƒì„± ë° ë°ì´í„° ì €ì¥ ì¤‘...")
    vector_store = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory=PERSIST_DIRECTORY
    )
    
    print(f"âœ… ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ! ì €ì¥ ê²½ë¡œ: {PERSIST_DIRECTORY}")
    return vector_store

def test_search(vector_store, query_text):
    print("\n" + "="*30)
    print(f"ğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: '{query_text}'")
    print("="*30)
    
    results = vector_store.similarity_search(query_text, k=3)
    
    for i, doc in enumerate(results):
        print(f"\n[ê²°ê³¼ {i+1}]")
        print(f"ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100].replace(chr(10), ' ')}...") 

if __name__ == "__main__":
    db = build_vector_db()
    # í…ŒìŠ¤íŠ¸: ì´ì œ ê¸°ì—… ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ì´ ì˜ ë˜ëŠ”ì§€ í™•ì¸
    test_search(db, "IT/ì›¹/í†µì‹ _í…Œí¬ ê¸°ì—…ì˜ ì¥ì ì€?")