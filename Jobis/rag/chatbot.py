import os
from dotenv import load_dotenv

# LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# ==========================================
# 1. ì„¤ì • ë° ê²½ë¡œ
# ==========================================
load_dotenv() # .env íŒŒì¼ ë¡œë“œ

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PERSIST_DIRECTORY = os.path.join(BASE_DIR, 'data', 'chroma_db')

# ì„ë² ë”© ëª¨ë¸ (DB ì €ì¥ ë•Œì™€ ë™ì¼í•´ì•¼ í•¨)
EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L12-v2"

# LLM ëª¨ë¸ ì„¤ì • (Gemini-2.5-flash)
LLM_MODEL_NAME = "gemini-2.5-flash"

class JobisChatbot:
    def __init__(self):
        self.vector_store = self._load_vector_db()
        self.retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3} # ìƒìœ„ 3ê°œ ë¬¸ì„œ ì°¸ì¡°
        )
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.2, # ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì„ ìœ„í•´ ì°½ì˜ì„± ë‚®ì¶¤
            google_api_key=os.getenv("GOOGLE_API_KEY")
        )
        self.chain = self._build_chain()

    def _load_vector_db(self):
        """ì €ì¥ëœ ChromaDBë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
        print("ğŸ’¾ Loading Vector DB...")
        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        return Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=embeddings
        )

    def _build_chain(self):
        """RAG ì²´ì¸(íŒŒì´í”„ë¼ì¸)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: LLMì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê³  ë‹µë³€ í˜•ì‹ì„ ì§€ì •
        template = """
        ë‹¹ì‹ ì€ êµ¬ì§ìë“¤ì„ ë•ëŠ” ì±„ìš© ì •ë³´ ì „ë¬¸ê°€ 'JOBIS(ìë¹„ìŠ¤)'ì…ë‹ˆë‹¤.
        ì•„ë˜ ì œê³µëœ [ê´€ë ¨ ê¸°ì—… ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        
        ì •ë³´ê°€ ì—†ë‹¤ë©´ "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ê¸°ì—…ì´ë‚˜ ë‚´ìš©ì— ëŒ€í•œ ì •ë³´ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.
        ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
        
        [ê´€ë ¨ ê¸°ì—… ì •ë³´]:
        {context}
        
        ì§ˆë¬¸: {question}
        
        ë‹µë³€:
        """
        
        prompt = PromptTemplate.from_template(template)
        
        # LangChain Runnable ì—°ê²° (Retriever -> Prompt -> LLM -> String Output)
        chain = (
            {"context": self.retriever | self._format_docs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )
        return chain

    def _format_docs(self, docs):
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ë¡œ í•©ì¹©ë‹ˆë‹¤."""
        return "\n\n".join([f"<ê¸°ì—…ëª…: {doc.metadata['company_name']}>\n{doc.page_content}" for doc in docs])

    def ask(self, query):
        """ì§ˆë¬¸ì„ ë°›ì•„ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not query:
            return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return self.chain.invoke(query)

# ==========================================
# 2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ ì‘ë™)
# ==========================================
if __name__ == "__main__":
    # API í‚¤ í™•ì¸
    if not os.getenv("GOOGLE_API_KEY"):
        print("âŒ Error: .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    print("ğŸ¤– ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
    bot = JobisChatbot()
    
    print("\nğŸ’¬ ì±—ë´‡ê³¼ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    while True:
        user_input = input("\nì§ˆë¬¸: ")
        if user_input.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
            break
        
        response = bot.ask(user_input)
        print(f"ë‹µë³€: {response}")